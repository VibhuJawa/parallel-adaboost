{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praateek/miniconda3/envs/twitter/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "num_egs = 5\n",
    "num_features = 2\n",
    "num_classifiers = 3\n",
    "\n",
    "X = np.zeros((num_egs,num_features))\n",
    "labels = np.zeros(num_egs)\n",
    "X[0][0]=10; labels[0] = 1;\n",
    "X[1][0]=30; labels[1] = 1;\n",
    "X[2][0]=40; labels[2] = -1;\n",
    "X[3][0]=60; labels[3] = -1;\n",
    "X[4][0]=90; labels[4] = 1;\n",
    "\n",
    "X[0][1]=40; \n",
    "X[1][1]=50; \n",
    "X[2][1]=40; \n",
    "X[3][1]=50; \n",
    "X[4][1]=40; \n",
    "\n",
    "# X[0][0]=10; labels[0] = 1;\n",
    "# X[1][0]=20; labels[1] = -1;\n",
    "# X[2][0]=30; labels[2] = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C++ like data structure\n",
    "class Decision_Direction_Error():\n",
    "    def __init__(self, error, direction):\n",
    "        self.error = error\n",
    "        self.direction = direction\n",
    "\n",
    "class DecisionStump():\n",
    "    def __init__(self, criteria='gini'):\n",
    "        self.criteria = criteria\n",
    "\n",
    "    \n",
    "    def get_error_curr_feature_val(labels, weights, feature_vals, split_value):\n",
    "        for i in range(self.weights):\n",
    "            # x[i] < c should be -1\n",
    "            \n",
    "            if ( ((feature_vals[i] <= split_value) and (labels[i]!=-1)) or \n",
    "                ((feature_vals[i] > split_val) and (labels[i]!=1)))\n",
    "            {\n",
    "                curr_error += weights[i];\n",
    "            }\n",
    "            \n",
    "            sol = Decision_Direction_Error(curr_error, 1)\n",
    "            \n",
    "            if curr_error < 0.5:\n",
    "                sol.direction = 1\n",
    "                sol.error = curr_error\n",
    "            else:\n",
    "                \n",
    "        \n",
    "    \n",
    "    def get_feature_threshold_curr_feature(labels, weights, feature_vals, unique_feature_vals):\n",
    "        for i in range(len(unique_feature_vals)):\n",
    "            self.get_error_curr_feature_val(labels, weights, feature_vals, unique_feature_vals[i])\n",
    "        \n",
    "    def get_best_feature_stump(self, labels, X_T, weights unique_feature_vals):\n",
    "        \n",
    "        self.num_features = len(X_T)\n",
    "        self.num_egs = len(X_T[0])\n",
    "        \n",
    "        best_error = float('inf')\n",
    "        \n",
    "        for i in range(self.num_features):\n",
    "            best_stump = get_feature_threshold_curr_feature(labels, weights, feature_vals[i], \n",
    "                                                            unique_feature_vals[i])\n",
    "        \n",
    "\n",
    "            \n",
    "    def fit(X, y):\n",
    "        num_egs = len(X)\n",
    "        num_features = len(X[0])\n",
    "        # Let's sort each feature by value initially\n",
    "        # This way we don't have to sort every time\n",
    "        for feature in range(num_features):\n",
    "            indices = np.argsort( X[:,feature] );\n",
    "            X_temp = X[indices]\n",
    "            \n",
    "\n",
    "class AdaBoost():\n",
    "    def __init__(self, num_classifiers='3'):\n",
    "        self.num_classifiers = num_classifiers\n",
    "    \n",
    "    def get_unique_feature_vals(self,X_T):\n",
    "        '''\n",
    "            Args:\n",
    "                x : dataset\n",
    "                \n",
    "            Returns:\n",
    "                feature_midpoints : For each feature returns a sorted list of mid points \n",
    "                                    of every two consecutive unique features\n",
    "            \n",
    "            Complexity:\n",
    "               (Old) :  M + N * M + M * NlogN + M * N\n",
    "               (New) : M * N log N + M * N\n",
    "               \n",
    "        '''\n",
    "\n",
    "        \n",
    "        X_copy = []     \n",
    "        feature_midpoints = []\n",
    "\n",
    "        # M * n log * n\n",
    "        for i in range(self.num_features):\n",
    "            X_copy.append(sorted(X_T[i]))\n",
    "        \n",
    "        # Get mid points of sorted unique values M * N\n",
    "        for i in range(self.num_features):\n",
    "            current = []\n",
    "            j = 0\n",
    "            while (j < self.num_egs - 1):\n",
    "                k = j + 1\n",
    "                while(X_copy[i][j] == X_copy[i][k] and k < self.num_egs - 1):\n",
    "                    k += 1\n",
    "                midpoint = (X_copy[i][j] + X_copy[i][k])/2\n",
    "                current.append(midpoint)\n",
    "                j = k\n",
    "            feature_midpoints.append(current)\n",
    "                            \n",
    "        return feature_midpoints\n",
    "    \n",
    "    def get_feature_threshold_curr_feature():\n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit_weak_classifers(self, labels, X_T, unique_feature_vals):\n",
    "        weights = np.ones(self.num_egs)/len(self.num_features)\n",
    "        classifiers = []\n",
    "        for t in range(self.num_classifiers):\n",
    "            clf = self.get_best_feature_stump(labels, X_T, weights, unique_feature_vals);\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.num_egs = len(X)\n",
    "        self.num_features = len(X[0])\n",
    "        X_T = X.T\n",
    "        classifiers = []\n",
    "        unique_feature_vals = self.get_unique_feature_vals(X_T)\n",
    "            \n",
    "#         for t in range(self.num_classifiers):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoost()\n",
    "clf.fit(X,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "2.5\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "A = [1,1,1,1,1,2,2,2,3,3,3,4]\n",
    "j = 0\n",
    "while (j < len(A) - 1):\n",
    "    k = j + 1\n",
    "    while(A[j] == A[k]):\n",
    "        k += 1\n",
    "    print((A[j] + A[k])/2)\n",
    "#     print(j,k)\n",
    "    j = k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
